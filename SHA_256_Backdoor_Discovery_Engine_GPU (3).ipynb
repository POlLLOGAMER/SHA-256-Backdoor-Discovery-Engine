{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qxdDaQErmEM",
        "outputId": "0f574a90-209b-4902-8b5b-9ecaf0415025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/2.9 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m2.8/2.9 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h======================================================================\n",
            "  ðŸš€ SHA-256 BACKDOOR DISCOVERY - GPU ACCELERATED\n",
            "======================================================================\n",
            "  Device: cuda\n",
            "  GPU: Tesla T4\n",
            "  Memory: 15.8 GB\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "  ðŸš€ SHA-256 BACKDOOR DISCOVERY - GPU ACCELERATED\n",
            "======================================================================\n",
            "\n",
            "DEVICE: cuda\n",
            "GPU: Tesla T4\n",
            "\n",
            "SPEEDUP FACTORS:\n",
            "â€¢ Batch SHA-256 on GPU: 100-1000x vs CPU sequential\n",
            "â€¢ Parallel population evaluation\n",
            "â€¢ Vectorized bit counting\n",
            "\n",
            "CONFIGURATION OPTIONS:\n",
            "â€¢ Population size: More genomes = better exploration\n",
            "â€¢ Batch size: More messages tested per genome\n",
            "â€¢ Generations: More evolution iterations\n",
            "\n",
            "EXPECTED PERFORMANCE:\n",
            "â€¢ GPU: ~1-10 million hashes/second\n",
            "â€¢ CPU: ~10-100 thousand hashes/second\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "OPTIONS:\n",
            "  1. Quick search (50 gen, 50 pop, 2 runs)\n",
            "  2. Standard search (100 gen, 100 pop, 3 runs)\n",
            "  3. Deep search (200 gen, 150 pop, 5 runs)\n",
            "  4. Intensive search (300 gen, 200 pop, 10 runs)\n",
            "  5. Custom search\n",
            "  q. Quit\n",
            "\n",
            "Choice: 3\n",
            "\n",
            "######################################################################\n",
            "#          ðŸš€ GPU-ACCELERATED BACKDOOR DISCOVERY             #\n",
            "######################################################################\n",
            "\n",
            "\n",
            "======================================================================\n",
            "  DISCOVERY RUN 1/5\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "  ðŸš€ GPU-ACCELERATED EVOLUTIONARY DISCOVERY\n",
            "======================================================================\n",
            "  Population: 150\n",
            "  Batch size: 2048\n",
            "  Batches per eval: 10\n",
            "  Tests per generation: 3,072,000\n",
            "\n",
            "  Initializing population...\n",
            "  Created 150 genomes\n",
            "\n",
            "  Gen   0 | Best: 166/256 | Avg: 159.9 | Ever: 166 | 219.50s | 0.03M H/s\n",
            "          | Constraints: 20z 26o | Diffs: 1\n",
            "\n",
            "  Gen   1 | Best: 168/256 | Avg: 160.1 | Ever: 168 | 217.96s | 0.03M H/s\n",
            "          | Constraints: 37z 30o | Diffs: 1\n",
            "\n",
            "  Gen   2 | Best: 169/256 | Avg: 160.4 | Ever: 169 | 217.11s | 0.03M H/s\n",
            "          | Constraints: 23z 17o | Diffs: 4\n",
            "\n",
            "  Gen   3 | Best: 166/256 | Avg: 160.0 | Ever: 169 | 218.70s | 0.03M H/s\n",
            "          | Constraints: 35z 40o | Diffs: 5\n",
            "\n",
            "  Gen   4 | Best: 169/256 | Avg: 160.1 | Ever: 169 | 217.46s | 0.03M H/s\n",
            "          | Constraints: 35z 42o | Diffs: 3\n",
            "\n",
            "  Gen   5 | Best: 171/256 | Avg: 160.1 | Ever: 171 | 216.89s | 0.03M H/s\n",
            "          | Constraints: 66z 69o | Diffs: 5\n"
          ]
        }
      ],
      "source": [
        "#@title ðŸš€ SHA-256 BACKDOOR DISCOVERY - GPU ACCELERATED\n",
        "\n",
        "\"\"\"\n",
        "SHA-256 BACKDOOR DISCOVERY ENGINE - GPU ACCELERATED\n",
        "=====================================================\n",
        "\n",
        "Uses PyTorch/CUDA for massive parallelization:\n",
        "- Batch SHA-256 computation on GPU\n",
        "- Parallel population evaluation\n",
        "- Vectorized fitness calculation\n",
        "- 100-1000x speedup over CPU\n",
        "\n",
        "Expected: Evaluate thousands of conditions per second\n",
        "\"\"\"\n",
        "\n",
        "!pip install python-sat torch -q\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import hashlib\n",
        "import time\n",
        "import random\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import os\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"=\"*70)\n",
        "print(\"  ðŸš€ SHA-256 BACKDOOR DISCOVERY - GPU ACCELERATED\")\n",
        "print(\"=\"*70)\n",
        "print(f\"  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"  âš ï¸  No GPU detected - will use CPU (slower)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ============================================================\n",
        "# SHA-256 CONSTANTS (as torch tensors on GPU)\n",
        "# ============================================================\n",
        "\n",
        "K_CONSTANTS = torch.tensor([\n",
        "    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n",
        "    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n",
        "    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n",
        "    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n",
        "    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n",
        "    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n",
        "    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n",
        "    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2\n",
        "], dtype=torch.int64, device=device)\n",
        "\n",
        "H_INIT = torch.tensor([\n",
        "    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,\n",
        "    0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19\n",
        "], dtype=torch.int64, device=device)\n",
        "\n",
        "MASK32 = 0xFFFFFFFF\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# GPU-ACCELERATED SHA-256\n",
        "# ============================================================\n",
        "\n",
        "class SHA256_GPU:\n",
        "    \"\"\"\n",
        "    Vectorized SHA-256 implementation on GPU.\n",
        "    Processes multiple messages in parallel.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def rotr(x, n):\n",
        "        \"\"\"Rotate right (circular shift)\"\"\"\n",
        "        return ((x >> n) | (x << (32 - n))) & MASK32\n",
        "\n",
        "    @staticmethod\n",
        "    def shr(x, n):\n",
        "        \"\"\"Shift right\"\"\"\n",
        "        return x >> n\n",
        "\n",
        "    @staticmethod\n",
        "    def ch(e, f, g):\n",
        "        \"\"\"Choice function\"\"\"\n",
        "        return (e & f) ^ ((~e) & g) & MASK32\n",
        "\n",
        "    @staticmethod\n",
        "    def maj(a, b, c):\n",
        "        \"\"\"Majority function\"\"\"\n",
        "        return (a & b) ^ (a & c) ^ (b & c)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigma0(x):\n",
        "        \"\"\"Ïƒ0 function\"\"\"\n",
        "        return SHA256_GPU.rotr(x, 7) ^ SHA256_GPU.rotr(x, 18) ^ SHA256_GPU.shr(x, 3)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigma1(x):\n",
        "        \"\"\"Ïƒ1 function\"\"\"\n",
        "        return SHA256_GPU.rotr(x, 17) ^ SHA256_GPU.rotr(x, 19) ^ SHA256_GPU.shr(x, 10)\n",
        "\n",
        "    @staticmethod\n",
        "    def Sigma0(x):\n",
        "        \"\"\"Î£0 function\"\"\"\n",
        "        return SHA256_GPU.rotr(x, 2) ^ SHA256_GPU.rotr(x, 13) ^ SHA256_GPU.rotr(x, 22)\n",
        "\n",
        "    @staticmethod\n",
        "    def Sigma1(x):\n",
        "        \"\"\"Î£1 function\"\"\"\n",
        "        return SHA256_GPU.rotr(x, 6) ^ SHA256_GPU.rotr(x, 11) ^ SHA256_GPU.rotr(x, 25)\n",
        "\n",
        "    @staticmethod\n",
        "    def hash_batch(messages):\n",
        "        \"\"\"\n",
        "        Hash a batch of messages on GPU.\n",
        "\n",
        "        Args:\n",
        "            messages: Tensor of shape (batch_size, 16) containing 32-bit words\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, 8) containing hash words\n",
        "        \"\"\"\n",
        "        batch_size = messages.shape[0]\n",
        "\n",
        "        # Ensure on correct device\n",
        "        messages = messages.to(device).long()\n",
        "\n",
        "        # Message schedule\n",
        "        W = torch.zeros((batch_size, 64), dtype=torch.int64, device=device)\n",
        "        W[:, :16] = messages & MASK32\n",
        "\n",
        "        for t in range(16, 64):\n",
        "            s0 = SHA256_GPU.sigma0(W[:, t-15])\n",
        "            s1 = SHA256_GPU.sigma1(W[:, t-2])\n",
        "            W[:, t] = (W[:, t-16] + s0 + W[:, t-7] + s1) & MASK32\n",
        "\n",
        "        # Initialize working variables\n",
        "        a = H_INIT[0].expand(batch_size).clone()\n",
        "        b = H_INIT[1].expand(batch_size).clone()\n",
        "        c = H_INIT[2].expand(batch_size).clone()\n",
        "        d = H_INIT[3].expand(batch_size).clone()\n",
        "        e = H_INIT[4].expand(batch_size).clone()\n",
        "        f = H_INIT[5].expand(batch_size).clone()\n",
        "        g = H_INIT[6].expand(batch_size).clone()\n",
        "        h = H_INIT[7].expand(batch_size).clone()\n",
        "\n",
        "        # Compression\n",
        "        for t in range(64):\n",
        "            S1 = SHA256_GPU.Sigma1(e)\n",
        "            ch = SHA256_GPU.ch(e, f, g)\n",
        "            temp1 = (h + S1 + ch + K_CONSTANTS[t] + W[:, t]) & MASK32\n",
        "            S0 = SHA256_GPU.Sigma0(a)\n",
        "            maj = SHA256_GPU.maj(a, b, c)\n",
        "            temp2 = (S0 + maj) & MASK32\n",
        "\n",
        "            h = g\n",
        "            g = f\n",
        "            f = e\n",
        "            e = (d + temp1) & MASK32\n",
        "            d = c\n",
        "            c = b\n",
        "            b = a\n",
        "            a = (temp1 + temp2) & MASK32\n",
        "\n",
        "        # Final hash\n",
        "        result = torch.stack([\n",
        "            (a + H_INIT[0]) & MASK32,\n",
        "            (b + H_INIT[1]) & MASK32,\n",
        "            (c + H_INIT[2]) & MASK32,\n",
        "            (d + H_INIT[3]) & MASK32,\n",
        "            (e + H_INIT[4]) & MASK32,\n",
        "            (f + H_INIT[5]) & MASK32,\n",
        "            (g + H_INIT[6]) & MASK32,\n",
        "            (h + H_INIT[7]) & MASK32,\n",
        "        ], dim=1)\n",
        "\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def count_matching_bits_batch(hash_a, hash_b):\n",
        "        \"\"\"\n",
        "        Count matching bits between two batches of hashes.\n",
        "\n",
        "        Returns: Tensor of shape (batch_size,) with matching bit counts\n",
        "        \"\"\"\n",
        "        # XOR to find differences\n",
        "        xor = hash_a ^ hash_b\n",
        "\n",
        "        # Count zeros (matching bits) using popcount\n",
        "        # PyTorch doesn't have popcount, so we do it manually\n",
        "        matching = torch.zeros(xor.shape[0], dtype=torch.int64, device=device)\n",
        "\n",
        "        for word in range(8):\n",
        "            word_xor = xor[:, word]\n",
        "            # Count set bits in XOR (these are different bits)\n",
        "            diff_bits = torch.zeros_like(word_xor)\n",
        "            temp = word_xor\n",
        "            for _ in range(32):\n",
        "                diff_bits += temp & 1\n",
        "                temp = temp >> 1\n",
        "            matching += 32 - diff_bits\n",
        "\n",
        "        return matching\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FAST BATCH DIFFERENTIAL TESTER\n",
        "# ============================================================\n",
        "\n",
        "class BatchDifferentialTester:\n",
        "    \"\"\"\n",
        "    GPU-accelerated batch testing of backdoor conditions.\n",
        "    Tests hundreds/thousands of message pairs simultaneously.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, batch_size=1024):\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def bits_to_words(self, bits_batch):\n",
        "        \"\"\"\n",
        "        Convert batch of 512 bits to 16 words.\n",
        "        bits_batch: (batch_size, 512) tensor\n",
        "        Returns: (batch_size, 16) tensor of 32-bit words\n",
        "        \"\"\"\n",
        "        batch_size = bits_batch.shape[0]\n",
        "        words = torch.zeros((batch_size, 16), dtype=torch.int64, device=device)\n",
        "\n",
        "        for w in range(16):\n",
        "            word_bits = bits_batch[:, w*32:(w+1)*32]\n",
        "            # Convert bits to word\n",
        "            for b in range(32):\n",
        "                words[:, w] += word_bits[:, b].long() << b\n",
        "\n",
        "        return words\n",
        "\n",
        "    def generate_messages_batch(self, msg_constraints, diff_constraints, batch_size):\n",
        "        \"\"\"\n",
        "        Generate batch of message pairs satisfying constraints.\n",
        "\n",
        "        Returns: (messages_A, messages_B) as word tensors\n",
        "        \"\"\"\n",
        "        # Generate random bits\n",
        "        A_bits = torch.randint(0, 2, (batch_size, 512), dtype=torch.int64, device=device)\n",
        "\n",
        "        # Apply message constraints\n",
        "        constraint_mask = torch.tensor(msg_constraints, device=device)\n",
        "\n",
        "        # Where constraint == 1, force to 0\n",
        "        zero_mask = (constraint_mask == 1)\n",
        "        A_bits[:, zero_mask] = 0\n",
        "\n",
        "        # Where constraint == 2, force to 1\n",
        "        one_mask = (constraint_mask == 2)\n",
        "        A_bits[:, one_mask] = 1\n",
        "\n",
        "        # Generate differential\n",
        "        diff_bits = torch.zeros((batch_size, 512), dtype=torch.int64, device=device)\n",
        "        diff_mask = torch.tensor(diff_constraints, device=device)\n",
        "\n",
        "        # Where diff_constraint == 2, set to 1\n",
        "        diff_active = (diff_mask == 2)\n",
        "        diff_bits[:, diff_active] = 1\n",
        "\n",
        "        # Ensure at least one diff bit\n",
        "        if diff_bits.sum() == 0:\n",
        "            diff_bits[:, 0] = 1\n",
        "\n",
        "        # B = A XOR diff\n",
        "        B_bits = A_bits ^ diff_bits\n",
        "\n",
        "        # Convert to words\n",
        "        A_words = self.bits_to_words(A_bits)\n",
        "        B_words = self.bits_to_words(B_bits)\n",
        "\n",
        "        return A_words, B_words, A_bits, B_bits\n",
        "\n",
        "    def test_condition(self, msg_constraints, diff_constraints, correlations=None, num_batches=10):\n",
        "        \"\"\"\n",
        "        Test a backdoor condition with GPU acceleration.\n",
        "\n",
        "        Returns: (best_matching, best_A, best_B, hash_A, hash_B)\n",
        "        \"\"\"\n",
        "        best_matching = 0\n",
        "        best_A = None\n",
        "        best_B = None\n",
        "        best_hash_A = None\n",
        "        best_hash_B = None\n",
        "\n",
        "        for _ in range(num_batches):\n",
        "            # Generate batch\n",
        "            A_words, B_words, A_bits, B_bits = self.generate_messages_batch(\n",
        "                msg_constraints, diff_constraints, self.batch_size\n",
        "            )\n",
        "\n",
        "            # Hash both batches\n",
        "            hash_A = SHA256_GPU.hash_batch(A_words)\n",
        "            hash_B = SHA256_GPU.hash_batch(B_words)\n",
        "\n",
        "            # Count matching bits\n",
        "            matching = SHA256_GPU.count_matching_bits_batch(hash_A, hash_B)\n",
        "\n",
        "            # Find best in batch\n",
        "            batch_best_idx = matching.argmax().item()\n",
        "            batch_best_matching = matching[batch_best_idx].item()\n",
        "\n",
        "            if batch_best_matching > best_matching:\n",
        "                best_matching = batch_best_matching\n",
        "\n",
        "                # Extract best messages\n",
        "                best_A_bits = A_bits[batch_best_idx].cpu().numpy()\n",
        "                best_B_bits = B_bits[batch_best_idx].cpu().numpy()\n",
        "\n",
        "                # Convert to bytes\n",
        "                def bits_to_bytes(bits):\n",
        "                    words = []\n",
        "                    for w in range(16):\n",
        "                        val = sum(int(bits[w*32 + b]) << b for b in range(32))\n",
        "                        words.append(val)\n",
        "                    return b''.join(w.to_bytes(4, 'big') for w in words)\n",
        "\n",
        "                best_A = bits_to_bytes(best_A_bits)\n",
        "                best_B = bits_to_bytes(best_B_bits)\n",
        "\n",
        "                # Get hash hex\n",
        "                best_hash_A = ''.join(f'{int(h):08x}' for h in hash_A[batch_best_idx].cpu().numpy())\n",
        "                best_hash_B = ''.join(f'{int(h):08x}' for h in hash_B[batch_best_idx].cpu().numpy())\n",
        "\n",
        "                if best_matching == 256:\n",
        "                    break\n",
        "\n",
        "            if best_matching == 256:\n",
        "                break\n",
        "\n",
        "        return best_matching, best_A, best_B, best_hash_A, best_hash_B\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# GPU-ACCELERATED BACKDOOR GENOME\n",
        "# ============================================================\n",
        "\n",
        "class BackdoorGenome:\n",
        "    \"\"\"Represents a potential backdoor condition\"\"\"\n",
        "\n",
        "    def __init__(self, genome_size=512):\n",
        "        self.genome_size = genome_size\n",
        "        self.msg_constraints = np.zeros(genome_size, dtype=np.int8)\n",
        "        self.diff_constraints = np.zeros(genome_size, dtype=np.int8)\n",
        "        self.correlations = []\n",
        "\n",
        "        self.fitness = 0\n",
        "        self.matching_bits = 0\n",
        "        self.is_collision = False\n",
        "        self.msg_A = None\n",
        "        self.msg_B = None\n",
        "        self.hash_A = None\n",
        "        self.hash_B = None\n",
        "\n",
        "        self.generation = 0\n",
        "        self.parent_fitness = 0\n",
        "\n",
        "    def randomize(self, constraint_density=0.05, diff_density=0.01):\n",
        "        \"\"\"Create random genome\"\"\"\n",
        "        for i in range(self.genome_size):\n",
        "            if random.random() < constraint_density:\n",
        "                self.msg_constraints[i] = random.choice([1, 2])\n",
        "\n",
        "        num_diffs = max(1, int(self.genome_size * diff_density))\n",
        "        diff_positions = random.sample(range(self.genome_size), min(num_diffs, 10))\n",
        "        for pos in diff_positions:\n",
        "            self.diff_constraints[pos] = 2\n",
        "\n",
        "    def mutate(self, mutation_rate=0.1, generation=0):\n",
        "        \"\"\"Mutate genome\"\"\"\n",
        "        child = BackdoorGenome(self.genome_size)\n",
        "        child.msg_constraints = self.msg_constraints.copy()\n",
        "        child.diff_constraints = self.diff_constraints.copy()\n",
        "        child.correlations = self.correlations.copy()\n",
        "        child.generation = generation\n",
        "        child.parent_fitness = self.fitness\n",
        "\n",
        "        adaptive_rate = mutation_rate * (1.0 + 0.5 * (256 - self.matching_bits) / 256)\n",
        "\n",
        "        for i in range(self.genome_size):\n",
        "            if random.random() < adaptive_rate:\n",
        "                if self.msg_constraints[i] == 0:\n",
        "                    child.msg_constraints[i] = random.choice([1, 2])\n",
        "                elif random.random() < 0.3:\n",
        "                    child.msg_constraints[i] = 0\n",
        "                else:\n",
        "                    child.msg_constraints[i] = 3 - self.msg_constraints[i]\n",
        "\n",
        "        for i in range(self.genome_size):\n",
        "            if random.random() < adaptive_rate * 0.5:\n",
        "                if self.diff_constraints[i] == 0:\n",
        "                    if random.random() < 0.1:\n",
        "                        child.diff_constraints[i] = 2\n",
        "                else:\n",
        "                    if random.random() < 0.3:\n",
        "                        child.diff_constraints[i] = 0\n",
        "\n",
        "        return child\n",
        "\n",
        "    def crossover(self, other, generation=0):\n",
        "        \"\"\"Crossover with another genome\"\"\"\n",
        "        child = BackdoorGenome(self.genome_size)\n",
        "        child.generation = generation\n",
        "        child.parent_fitness = max(self.fitness, other.fitness)\n",
        "\n",
        "        p1 = random.randint(0, self.genome_size - 1)\n",
        "        p2 = random.randint(p1, self.genome_size)\n",
        "\n",
        "        child.msg_constraints[:p1] = self.msg_constraints[:p1]\n",
        "        child.msg_constraints[p1:p2] = other.msg_constraints[p1:p2]\n",
        "        child.msg_constraints[p2:] = self.msg_constraints[p2:]\n",
        "\n",
        "        if self.fitness >= other.fitness:\n",
        "            child.diff_constraints = self.diff_constraints.copy()\n",
        "        else:\n",
        "            child.diff_constraints = other.diff_constraints.copy()\n",
        "\n",
        "        return child\n",
        "\n",
        "    def get_summary(self):\n",
        "        \"\"\"Human-readable summary\"\"\"\n",
        "        return {\n",
        "            'msg_zeros': int(np.sum(self.msg_constraints == 1)),\n",
        "            'msg_ones': int(np.sum(self.msg_constraints == 2)),\n",
        "            'diff_bits': int(np.sum(self.diff_constraints == 2)),\n",
        "            'matching': self.matching_bits,\n",
        "            'fitness': self.fitness\n",
        "        }\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'msg_constraints': self.msg_constraints.tolist(),\n",
        "            'diff_constraints': self.diff_constraints.tolist(),\n",
        "            'matching_bits': self.matching_bits,\n",
        "            'is_collision': self.is_collision,\n",
        "            'msg_A': self.msg_A.hex() if self.msg_A else None,\n",
        "            'msg_B': self.msg_B.hex() if self.msg_B else None,\n",
        "            'hash_A': self.hash_A,\n",
        "            'hash_B': self.hash_B\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# GPU-ACCELERATED EVOLUTIONARY ENGINE\n",
        "# ============================================================\n",
        "\n",
        "class GPUBackdoorDiscovery:\n",
        "    \"\"\"\n",
        "    GPU-accelerated evolutionary backdoor discovery.\n",
        "\n",
        "    Key optimizations:\n",
        "    1. Batch SHA-256 on GPU\n",
        "    2. Parallel population evaluation\n",
        "    3. Vectorized fitness calculation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, population_size=100, batch_size=2048):\n",
        "        self.population_size = population_size\n",
        "        self.batch_size = batch_size\n",
        "        self.tester = BatchDifferentialTester(batch_size)\n",
        "\n",
        "        self.population = []\n",
        "        self.generation = 0\n",
        "        self.best_ever = None\n",
        "        self.history = []\n",
        "\n",
        "        self.stats = {\n",
        "            'generations': 0,\n",
        "            'evaluations': 0,\n",
        "            'hashes_computed': 0,\n",
        "            'best_matching': 0,\n",
        "            'collisions_found': 0\n",
        "        }\n",
        "\n",
        "    def initialize_population(self):\n",
        "        \"\"\"Create diverse initial population\"\"\"\n",
        "        print(\"\\n  Initializing population...\")\n",
        "        self.population = []\n",
        "\n",
        "        # Strategy mix for diversity\n",
        "        strategies = [\n",
        "            (0.02, 0.002),  # Very sparse\n",
        "            (0.05, 0.002),  # Sparse\n",
        "            (0.10, 0.003),  # Medium\n",
        "            (0.15, 0.004),  # Dense\n",
        "            (0.08, 0.005),  # More diffs\n",
        "            (0.12, 0.002),  # Dense msg, sparse diff\n",
        "        ]\n",
        "\n",
        "        per_strategy = self.population_size // len(strategies)\n",
        "\n",
        "        for constraint_d, diff_d in strategies:\n",
        "            for _ in range(per_strategy):\n",
        "                genome = BackdoorGenome()\n",
        "                genome.randomize(constraint_d, diff_d)\n",
        "                self.population.append(genome)\n",
        "\n",
        "        # Fill remaining\n",
        "        while len(self.population) < self.population_size:\n",
        "            genome = BackdoorGenome()\n",
        "            genome.randomize(random.uniform(0.03, 0.15), random.uniform(0.002, 0.006))\n",
        "            self.population.append(genome)\n",
        "\n",
        "        print(f\"  Created {len(self.population)} genomes\")\n",
        "\n",
        "    def evaluate_genome(self, genome, num_batches=5):\n",
        "        \"\"\"Evaluate single genome using GPU batch testing\"\"\"\n",
        "        matching, msg_A, msg_B, hash_A, hash_B = self.tester.test_condition(\n",
        "            genome.msg_constraints,\n",
        "            genome.diff_constraints,\n",
        "            genome.correlations,\n",
        "            num_batches=num_batches\n",
        "        )\n",
        "\n",
        "        genome.matching_bits = matching\n",
        "        genome.msg_A = msg_A\n",
        "        genome.msg_B = msg_B\n",
        "        genome.hash_A = hash_A\n",
        "        genome.hash_B = hash_B\n",
        "        genome.is_collision = (matching == 256)\n",
        "\n",
        "        constraint_count = np.sum(genome.msg_constraints != 0)\n",
        "        genome.fitness = matching - 0.001 * constraint_count\n",
        "\n",
        "        self.stats['evaluations'] += 1\n",
        "        self.stats['hashes_computed'] += num_batches * self.batch_size * 2\n",
        "\n",
        "        return genome\n",
        "\n",
        "    def evaluate_population(self, num_batches=5):\n",
        "        \"\"\"Evaluate all genomes\"\"\"\n",
        "        for genome in self.population:\n",
        "            self.evaluate_genome(genome, num_batches)\n",
        "\n",
        "    def select_parents(self, tournament_size=5):\n",
        "        \"\"\"Tournament selection\"\"\"\n",
        "        parents = []\n",
        "        for _ in range(self.population_size):\n",
        "            tournament = random.sample(self.population, min(tournament_size, len(self.population)))\n",
        "            winner = max(tournament, key=lambda g: g.fitness)\n",
        "            parents.append(winner)\n",
        "        return parents\n",
        "\n",
        "    def create_next_generation(self):\n",
        "        \"\"\"Create next generation\"\"\"\n",
        "        self.population.sort(key=lambda g: g.fitness, reverse=True)\n",
        "\n",
        "        elite_count = max(2, self.population_size // 10)\n",
        "        new_population = self.population[:elite_count]\n",
        "\n",
        "        parents = self.select_parents()\n",
        "\n",
        "        while len(new_population) < self.population_size:\n",
        "            if random.random() < 0.7:\n",
        "                p1, p2 = random.sample(parents, 2)\n",
        "                child = p1.crossover(p2, self.generation + 1)\n",
        "            else:\n",
        "                parent = random.choice(parents)\n",
        "                child = parent.mutate(0.1, self.generation + 1)\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                child = child.mutate(0.05, self.generation + 1)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        self.population = new_population[:self.population_size]\n",
        "        self.generation += 1\n",
        "\n",
        "    def inject_diversity(self):\n",
        "        \"\"\"Inject fresh genomes\"\"\"\n",
        "        self.population.sort(key=lambda g: g.fitness, reverse=True)\n",
        "        inject_count = self.population_size // 5\n",
        "\n",
        "        for i in range(inject_count):\n",
        "            genome = BackdoorGenome()\n",
        "            genome.randomize(random.uniform(0.03, 0.12), random.uniform(0.002, 0.006))\n",
        "            self.population[-(i+1)] = genome\n",
        "\n",
        "    def run(self, max_generations=100, target_bits=256, batches_per_eval=8, verbose=True):\n",
        "        \"\"\"Run evolutionary search\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"  ðŸš€ GPU-ACCELERATED EVOLUTIONARY DISCOVERY\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"  Population: {self.population_size}\")\n",
        "        print(f\"  Batch size: {self.batch_size}\")\n",
        "        print(f\"  Batches per eval: {batches_per_eval}\")\n",
        "        print(f\"  Tests per generation: {self.population_size * batches_per_eval * self.batch_size:,}\")\n",
        "\n",
        "        self.initialize_population()\n",
        "\n",
        "        start_time = time.time()\n",
        "        no_improvement = 0\n",
        "        last_best = 0\n",
        "\n",
        "        for gen in range(max_generations):\n",
        "            self.generation = gen\n",
        "            gen_start = time.time()\n",
        "\n",
        "            # Evaluate\n",
        "            self.evaluate_population(num_batches=batches_per_eval)\n",
        "\n",
        "            # Track best\n",
        "            current_best = max(self.population, key=lambda g: g.matching_bits)\n",
        "\n",
        "            if self.best_ever is None or current_best.matching_bits > self.best_ever.matching_bits:\n",
        "                self.best_ever = BackdoorGenome()\n",
        "                self.best_ever.msg_constraints = current_best.msg_constraints.copy()\n",
        "                self.best_ever.diff_constraints = current_best.diff_constraints.copy()\n",
        "                self.best_ever.matching_bits = current_best.matching_bits\n",
        "                self.best_ever.fitness = current_best.fitness\n",
        "                self.best_ever.msg_A = current_best.msg_A\n",
        "                self.best_ever.msg_B = current_best.msg_B\n",
        "                self.best_ever.hash_A = current_best.hash_A\n",
        "                self.best_ever.hash_B = current_best.hash_B\n",
        "                self.best_ever.is_collision = current_best.is_collision\n",
        "                no_improvement = 0\n",
        "            else:\n",
        "                no_improvement += 1\n",
        "\n",
        "            # Stats\n",
        "            avg_matching = np.mean([g.matching_bits for g in self.population])\n",
        "            max_matching = max(g.matching_bits for g in self.population)\n",
        "            gen_time = time.time() - gen_start\n",
        "            total_time = time.time() - start_time\n",
        "            hashes_per_sec = self.stats['hashes_computed'] / total_time\n",
        "\n",
        "            self.history.append({\n",
        "                'generation': gen,\n",
        "                'avg_matching': avg_matching,\n",
        "                'max_matching': max_matching,\n",
        "                'best_ever': self.best_ever.matching_bits,\n",
        "                'time': gen_time\n",
        "            })\n",
        "\n",
        "            if verbose:\n",
        "                summary = current_best.get_summary()\n",
        "                print(f\"\\n  Gen {gen:3d} | Best: {max_matching:3d}/256 | \"\n",
        "                      f\"Avg: {avg_matching:.1f} | Ever: {self.best_ever.matching_bits:3d} | \"\n",
        "                      f\"{gen_time:.2f}s | {hashes_per_sec/1e6:.2f}M H/s\")\n",
        "                print(f\"          | Constraints: {summary['msg_zeros']}z {summary['msg_ones']}o | \"\n",
        "                      f\"Diffs: {summary['diff_bits']}\")\n",
        "\n",
        "            # Check collision\n",
        "            if current_best.is_collision:\n",
        "                print(\"\\n\" + \"ðŸš¨\"*30)\n",
        "                print(\"  COLLISION FOUND! BACKDOOR CONFIRMED!\")\n",
        "                print(\"ðŸš¨\"*30)\n",
        "                self.stats['collisions_found'] += 1\n",
        "                break\n",
        "\n",
        "            if current_best.matching_bits >= target_bits:\n",
        "                print(f\"\\n  Target {target_bits} bits reached!\")\n",
        "                break\n",
        "\n",
        "            # Diversity injection\n",
        "            if no_improvement >= 10:\n",
        "                if verbose:\n",
        "                    print(f\"  [Injecting diversity - stuck for {no_improvement} gens]\")\n",
        "                self.inject_diversity()\n",
        "                no_improvement = 0\n",
        "\n",
        "            self.create_next_generation()\n",
        "\n",
        "        self.stats['generations'] = self.generation\n",
        "        self.stats['best_matching'] = self.best_ever.matching_bits if self.best_ever else 0\n",
        "\n",
        "        # Final intensive search on best\n",
        "        if self.best_ever and self.best_ever.matching_bits >= 200 and not self.best_ever.is_collision:\n",
        "            print(\"\\n  Running intensive search on best candidate...\")\n",
        "            self.intensive_search(self.best_ever, iterations=50)\n",
        "\n",
        "        return self.best_ever\n",
        "\n",
        "    def intensive_search(self, genome, iterations=50):\n",
        "        \"\"\"Intensive search on a promising genome\"\"\"\n",
        "        best = genome\n",
        "\n",
        "        for i in range(iterations):\n",
        "            # Test with more batches\n",
        "            matching, msg_A, msg_B, hash_A, hash_B = self.tester.test_condition(\n",
        "                genome.msg_constraints,\n",
        "                genome.diff_constraints,\n",
        "                genome.correlations,\n",
        "                num_batches=20\n",
        "            )\n",
        "\n",
        "            if matching > best.matching_bits:\n",
        "                best.matching_bits = matching\n",
        "                best.msg_A = msg_A\n",
        "                best.msg_B = msg_B\n",
        "                best.hash_A = hash_A\n",
        "                best.hash_B = hash_B\n",
        "                best.is_collision = (matching == 256)\n",
        "                print(f\"    Intensive search: {matching}/256\")\n",
        "\n",
        "                if matching == 256:\n",
        "                    print(\"    COLLISION!\")\n",
        "                    break\n",
        "\n",
        "            # Try small mutations\n",
        "            mutant = genome.mutate(0.02)\n",
        "            matching2, msg_A2, msg_B2, hash_A2, hash_B2 = self.tester.test_condition(\n",
        "                mutant.msg_constraints,\n",
        "                mutant.diff_constraints,\n",
        "                mutant.correlations,\n",
        "                num_batches=10\n",
        "            )\n",
        "\n",
        "            if matching2 > best.matching_bits:\n",
        "                best = mutant\n",
        "                best.matching_bits = matching2\n",
        "                best.msg_A = msg_A2\n",
        "                best.msg_B = msg_B2\n",
        "                best.hash_A = hash_A2\n",
        "                best.hash_B = hash_B2\n",
        "                best.is_collision = (matching2 == 256)\n",
        "                genome = mutant\n",
        "                print(f\"    Mutation improved: {matching2}/256\")\n",
        "\n",
        "        if best.matching_bits > self.best_ever.matching_bits:\n",
        "            self.best_ever = best\n",
        "\n",
        "    def analyze_best(self):\n",
        "        \"\"\"Analyze best found condition\"\"\"\n",
        "        if not self.best_ever:\n",
        "            print(\"No best genome found\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"  BEST DISCOVERED CONDITION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        genome = self.best_ever\n",
        "\n",
        "        print(f\"\\n  Matching bits: {genome.matching_bits}/256\")\n",
        "        print(f\"  Is collision: {genome.is_collision}\")\n",
        "\n",
        "        # Constraint analysis\n",
        "        msg_zeros = np.sum(genome.msg_constraints == 1)\n",
        "        msg_ones = np.sum(genome.msg_constraints == 2)\n",
        "        diff_bits = np.sum(genome.diff_constraints == 2)\n",
        "\n",
        "        print(f\"\\n  CONSTRAINTS:\")\n",
        "        print(f\"    Bits forced to 0: {msg_zeros}\")\n",
        "        print(f\"    Bits forced to 1: {msg_ones}\")\n",
        "        print(f\"    Differential bits: {diff_bits}\")\n",
        "\n",
        "        # Show pattern\n",
        "        print(f\"\\n  MESSAGE CONSTRAINT PATTERN:\")\n",
        "        for word in range(16):\n",
        "            constrained = []\n",
        "            for bit in range(32):\n",
        "                idx = word * 32 + bit\n",
        "                if genome.msg_constraints[idx] == 1:\n",
        "                    constrained.append(f\"{bit}=0\")\n",
        "                elif genome.msg_constraints[idx] == 2:\n",
        "                    constrained.append(f\"{bit}=1\")\n",
        "            if constrained:\n",
        "                print(f\"    Word {word:2d}: {', '.join(constrained[:8])}{'...' if len(constrained) > 8 else ''}\")\n",
        "\n",
        "        print(f\"\\n  DIFFERENTIAL PATTERN:\")\n",
        "        for i in range(512):\n",
        "            if genome.diff_constraints[i] == 2:\n",
        "                word = i // 32\n",
        "                bit = i % 32\n",
        "                print(f\"    Word {word}, Bit {bit}\")\n",
        "\n",
        "        print(f\"\\n  MESSAGES:\")\n",
        "        if genome.msg_A:\n",
        "            print(f\"    A: {genome.msg_A.hex()}\")\n",
        "        if genome.msg_B:\n",
        "            print(f\"    B: {genome.msg_B.hex()}\")\n",
        "\n",
        "        print(f\"\\n  HASHES:\")\n",
        "        if genome.hash_A:\n",
        "            print(f\"    H(A): {genome.hash_A}\")\n",
        "        if genome.hash_B:\n",
        "            print(f\"    H(B): {genome.hash_B}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MULTI-RUN DISCOVERY\n",
        "# ============================================================\n",
        "\n",
        "class BackdoorHunterGPU:\n",
        "    \"\"\"Main interface for GPU-accelerated backdoor hunting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.all_discoveries = []\n",
        "        self.best_overall = None\n",
        "\n",
        "    def run(self, generations=100, population=100, batch_size=2048,\n",
        "            batches_per_eval=8, runs=3):\n",
        "        \"\"\"Run multiple discovery attempts\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"#\"*70)\n",
        "        print(\"#\" + \" \"*10 + \"ðŸš€ GPU-ACCELERATED BACKDOOR DISCOVERY\" + \" \"*13 + \"#\")\n",
        "        print(\"#\"*70)\n",
        "\n",
        "        total_start = time.time()\n",
        "\n",
        "        for run_idx in range(runs):\n",
        "            print(f\"\\n\\n{'='*70}\")\n",
        "            print(f\"  DISCOVERY RUN {run_idx + 1}/{runs}\")\n",
        "            print(f\"{'='*70}\")\n",
        "\n",
        "            # Clear GPU memory\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            engine = GPUBackdoorDiscovery(population_size=population, batch_size=batch_size)\n",
        "            best = engine.run(\n",
        "                max_generations=generations,\n",
        "                batches_per_eval=batches_per_eval,\n",
        "                verbose=True\n",
        "            )\n",
        "\n",
        "            if best:\n",
        "                self.all_discoveries.append(best)\n",
        "\n",
        "                if self.best_overall is None or best.matching_bits > self.best_overall.matching_bits:\n",
        "                    self.best_overall = best\n",
        "\n",
        "                if best.is_collision:\n",
        "                    self._report_collision(best)\n",
        "                    return best\n",
        "\n",
        "        total_time = time.time() - total_start\n",
        "        self._final_report(total_time)\n",
        "\n",
        "        return self.best_overall\n",
        "\n",
        "    def _report_collision(self, genome):\n",
        "        \"\"\"Report found collision\"\"\"\n",
        "        print(\"\\n\\n\" + \"ðŸš¨\"*35)\n",
        "        print(\"  CRITICAL: BACKDOOR DISCOVERED!\")\n",
        "        print(\"ðŸš¨\"*35)\n",
        "\n",
        "        print(f\"\\n  COLLISION CONDITION:\")\n",
        "        print(f\"    Bits forced to 0: {np.sum(genome.msg_constraints == 1)}\")\n",
        "        print(f\"    Bits forced to 1: {np.sum(genome.msg_constraints == 2)}\")\n",
        "        print(f\"    Differential bits: {np.sum(genome.diff_constraints == 2)}\")\n",
        "\n",
        "        print(f\"\\n  COLLIDING MESSAGES:\")\n",
        "        print(f\"    A: {genome.msg_A.hex()}\")\n",
        "        print(f\"    B: {genome.msg_B.hex()}\")\n",
        "\n",
        "        print(f\"\\n  SHARED HASH:\")\n",
        "        print(f\"    {genome.hash_A}\")\n",
        "\n",
        "        # Verify with hashlib\n",
        "        real_hash_A = hashlib.sha256(genome.msg_A).hexdigest()\n",
        "        real_hash_B = hashlib.sha256(genome.msg_B).hexdigest()\n",
        "\n",
        "        print(f\"\\n  VERIFICATION (hashlib):\")\n",
        "        print(f\"    H(A): {real_hash_A}\")\n",
        "        print(f\"    H(B): {real_hash_B}\")\n",
        "        print(f\"    Match: {real_hash_A == real_hash_B}\")\n",
        "\n",
        "        with open(\"sha256_backdoor_found.json\", \"w\") as f:\n",
        "            json.dump(genome.to_dict(), f, indent=2)\n",
        "        print(f\"\\n  Saved to: sha256_backdoor_found.json\")\n",
        "\n",
        "    def _final_report(self, total_time):\n",
        "        \"\"\"Final report\"\"\"\n",
        "        print(\"\\n\\n\" + \"=\"*70)\n",
        "        print(\"  DISCOVERY COMPLETE\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        print(f\"\\n  Total time: {total_time:.1f}s\")\n",
        "        print(f\"  Runs completed: {len(self.all_discoveries)}\")\n",
        "\n",
        "        if self.best_overall:\n",
        "            print(f\"\\n  BEST RESULT:\")\n",
        "            print(f\"    Matching bits: {self.best_overall.matching_bits}/256\")\n",
        "            print(f\"    Is collision: {self.best_overall.is_collision}\")\n",
        "\n",
        "            if self.best_overall.msg_A:\n",
        "                print(f\"\\n  MESSAGES:\")\n",
        "                print(f\"    A: {self.best_overall.msg_A.hex()}\")\n",
        "                print(f\"    B: {self.best_overall.msg_B.hex()}\")\n",
        "\n",
        "            if self.best_overall.hash_A:\n",
        "                print(f\"\\n  HASHES:\")\n",
        "                print(f\"    H(A): {self.best_overall.hash_A}\")\n",
        "                print(f\"    H(B): {self.best_overall.hash_B}\")\n",
        "\n",
        "            # Verify with hashlib\n",
        "            if self.best_overall.msg_A and self.best_overall.msg_B:\n",
        "                real_A = hashlib.sha256(self.best_overall.msg_A).hexdigest()\n",
        "                real_B = hashlib.sha256(self.best_overall.msg_B).hexdigest()\n",
        "\n",
        "                real_matching = sum(\n",
        "                    8 - bin(a ^ b).count('1')\n",
        "                    for a, b in zip(\n",
        "                        bytes.fromhex(real_A),\n",
        "                        bytes.fromhex(real_B)\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                print(f\"\\n  VERIFICATION (hashlib):\")\n",
        "                print(f\"    Real matching bits: {real_matching}/256\")\n",
        "\n",
        "        # Verdict\n",
        "        print(\"\\n\" + \"-\"*70)\n",
        "        if self.best_overall and self.best_overall.is_collision:\n",
        "            print(\"  ðŸš¨ VERDICT: BACKDOOR FOUND\")\n",
        "        elif self.best_overall and self.best_overall.matching_bits >= 200:\n",
        "            print(\"  âš ï¸  VERDICT: SUSPICIOUS - High correlation found\")\n",
        "        elif self.best_overall and self.best_overall.matching_bits >= 160:\n",
        "            print(\"  âš¡ VERDICT: ANOMALY - Above random baseline\")\n",
        "        else:\n",
        "            print(\"  âœ“ VERDICT: No backdoor detected\")\n",
        "\n",
        "        # Save all\n",
        "        if self.all_discoveries:\n",
        "            data = {\n",
        "                'best_matching': self.best_overall.matching_bits if self.best_overall else 0,\n",
        "                'discoveries': [g.to_dict() for g in self.all_discoveries]\n",
        "            }\n",
        "            with open(\"sha256_gpu_discoveries.json\", \"w\") as f:\n",
        "                json.dump(data, f, indent=2)\n",
        "            print(f\"\\n  Results saved to: sha256_gpu_discoveries.json\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"  ðŸš€ SHA-256 BACKDOOR DISCOVERY - GPU ACCELERATED\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(f\"\"\"\n",
        "DEVICE: {device}\n",
        "{'GPU: ' + torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU mode (slower)'}\n",
        "\n",
        "SPEEDUP FACTORS:\n",
        "â€¢ Batch SHA-256 on GPU: 100-1000x vs CPU sequential\n",
        "â€¢ Parallel population evaluation\n",
        "â€¢ Vectorized bit counting\n",
        "\n",
        "CONFIGURATION OPTIONS:\n",
        "â€¢ Population size: More genomes = better exploration\n",
        "â€¢ Batch size: More messages tested per genome\n",
        "â€¢ Generations: More evolution iterations\n",
        "\n",
        "EXPECTED PERFORMANCE:\n",
        "â€¢ GPU: ~1-10 million hashes/second\n",
        "â€¢ CPU: ~10-100 thousand hashes/second\n",
        "\"\"\")\n",
        "\n",
        "    hunter = BackdoorHunterGPU()\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "        print(\"OPTIONS:\")\n",
        "        print(\"  1. Quick search (50 gen, 50 pop, 2 runs)\")\n",
        "        print(\"  2. Standard search (100 gen, 100 pop, 3 runs)\")\n",
        "        print(\"  3. Deep search (200 gen, 150 pop, 5 runs)\")\n",
        "        print(\"  4. Intensive search (300 gen, 200 pop, 10 runs)\")\n",
        "        print(\"  5. Custom search\")\n",
        "        print(\"  q. Quit\")\n",
        "\n",
        "        choice = input(\"\\nChoice: \").strip().lower()\n",
        "\n",
        "        if choice == 'q':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        elif choice == '1':\n",
        "            hunter.run(generations=50, population=50, batch_size=1024,\n",
        "                      batches_per_eval=5, runs=2)\n",
        "\n",
        "        elif choice == '2':\n",
        "            hunter.run(generations=100, population=100, batch_size=2048,\n",
        "                      batches_per_eval=8, runs=3)\n",
        "\n",
        "        elif choice == '3':\n",
        "            hunter.run(generations=200, population=150, batch_size=2048,\n",
        "                      batches_per_eval=10, runs=5)\n",
        "\n",
        "        elif choice == '4':\n",
        "            hunter.run(generations=300, population=200, batch_size=4096,\n",
        "                      batches_per_eval=12, runs=10)\n",
        "\n",
        "        elif choice == '5':\n",
        "            try:\n",
        "                gens = int(input(\"Generations (default 100): \").strip() or \"100\")\n",
        "                pop = int(input(\"Population (default 100): \").strip() or \"100\")\n",
        "                batch = int(input(\"Batch size (default 2048): \").strip() or \"2048\")\n",
        "                batches = int(input(\"Batches per eval (default 8): \").strip() or \"8\")\n",
        "                runs = int(input(\"Runs (default 3): \").strip() or \"3\")\n",
        "\n",
        "                hunter.run(generations=gens, population=pop, batch_size=batch,\n",
        "                          batches_per_eval=batches, runs=runs)\n",
        "            except ValueError:\n",
        "                print(\"Invalid input\")\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}